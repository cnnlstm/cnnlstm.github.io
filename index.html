<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Yangyang Xu  </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css"> 
  <link rel="Bookmark" type="image/png" href="images/tab.ico" />
  <link rel="icon" type="image/png" href="images/tab.ico" />
  <link rel="shortcut icon" type="image/png" href="images/tab.ico" />

</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yangyang Xu </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> 
              I am currently working as a postdoctoral fellow at The University of Hong Kong(<a href="https://www.hku.hk/">HKU</a>), led by Prof. <a href="http://luoping.me/">Ping Luo</a>. Before that, I receive my doctorate  uder the supervision of Prof. <a href="https://shengfenghe.com/">Shengfeng He</a> and Prof. <a href="https://scut-mm.github.io/people.html/">Xuemiao Xu</a> at the South China University of Technology(<a href="https://www.scut.edu.cn/en/">SCUT</a>). 

              <br>My research interests include computer vision, image editing, generative models and transfer learning.

              </p>
 
 
              <p style="text-align:center">
                <a href="mailto:cnnlstm@gmail.com"> Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=SmlxBFAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://cnnlstm.github.io/YangyangXu_cv.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:100%;max-width:100%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
                                                                                                                          
                                                                                                                          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      <ul>

                      <li>03/02/2022: One Paper is accepted by CVPR. </li>
                      <li>12/22/2021: One Paper is accepted by TIP. </li>
                      <li>12/02/2021: Join the department of computer science, HKU, and start the postdoctoral phase.</li>
                      <li>08/13/2021: Passed the oral defense and became a <span style="color:rgb(224, 145, 92)"><b>Dr</b></span>.</li>
                      <li>07/23/2021: One Paper is accepted by ICCV.</li>
                      <li>06/09/2021: One Paper is accepted by TIP.</li>

                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>
        </tbody></table>
 
        <heading>Publications</heading>

        <p>Summary: CVPR & ICCV (2),  <i>IEEE</i> & <i>ACM</i> Transactions (8). </font> </p>

        <p><font face="Arial" size="3"> * Corresponding author; + Equal Contribution </p>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
   
     <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/faceswap.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle> High-resolution Face Swapping via Latent Semantics Disentanglement  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>,  Bailin Deng, Junle Wang, Yanqing Jing, Jia Pan and Shengfeng He*
              <br>
              <em> CVPR </em>, 2022   
              <br>
              <a href="https://https://arxiv.org/pdf/2203.15958.pdf">PDF</a> / 
              <a href="https://https://arxiv.org/pdf/2203.15958.pdf">Supp</a> / 
              <a href="https://github.com/cnnlstm/FSLSD_HiRes">Code</a>  
            </td>
     </tr> 
     <tr>

            <td style="padding:20px;width:25%;vertical-align:sub">
             <img src='images/propulse.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
                <papertitle> Pro-PULSE: Learning Progressive Encoders of Latent Semantics in GANs for Photo Upsampling  </papertitle>
              </a>
              <br>
              Yang Zhou+, <strong>Yangyang Xu</strong>+, Yong Du, Qiang Wen and Shengfeng He*
              <br>
              <em>IEEE TIP</em>, 2022   
              <br>
              <a href="https://ieeexplore.ieee.org/document/9678071">PDF</a>  /
              Supp / 
              Code 
            </td>

     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/icme.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Background Matting via Recursive Excitation  </papertitle>
              </a>
              <br>
              Junjie Deng+, <strong>Yangyang Xu</strong>+, Zeyang Zhou and Shengfeng He*
              <br>
              <em> ICME </em>, 2022   
              <br>
              PDF / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr>     


     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/inversion.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> From Continuity to Editability: Inverting GANs with Consecutive Images  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Yong Du, Wenpeng Xiao, Xuemiao Xu*, and Shengfeng He*
              <br>
              <em> ICCV </em>, 2021   
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_From_Continuity_to_Editability_Inverting_GANs_With_Consecutive_Images_ICCV_2021_paper.pdf">PDF</a> / 
              <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_From_Continuity_to_ICCV_2021_supplemental.pdf">Supp</a> / 
              <a href="https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs">Code</a>  
              <p></p>
            </td>
     </tr>     

     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/faceflow.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Multi-view Face Synthesis via Progressive Face Flow  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Xuemiao Xu*, Jianbo Jiao, Keke Li, Cheng Xu and Shengfeng He*
              <br>
              <em>IEEE TIP </em>, 2021   
              <br>
              <a href="https://ieeexplore.ieee.org/document/9466401">PDF</a> / 
              <a href="https://ieeexplore.ieee.org/document/9495995">Erratum</a> / 
              Code  
              <p></p>
            </td>
     </tr>  


     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/ham.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Holistically-Associated Transductive Zero-Shot Learning  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Xuemiao Xu*, Guoqiang Han, and Shengfeng He*
              <br>
              <em>IEEE TCDS </em>, 2021   
              <br>
              <a href="https://ieeexplore.ieee.org/document/9314882">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr>     



     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/tomm.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Invertible Grayscale with Sparsity Enforcing Priors  </papertitle>
              </a>
              <br>
              Yong Du, <strong>Yangyang Xu</strong>, Taizhong Ye, Qiang Wen, Chufeng Xiao, Junyu Dong, Guoqiang Han, Shengfeng He*
              <br>
              <em>ACM TOMM </em>, 2021   
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3451993">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr>     

     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/cod.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Deep Texture-Aware Features for Camouflaged Object Detection  </papertitle>
              </a>
              <br>
              Jingjing Ren, Xiaowei Hu, Lei Zhu, Xuemiao Xu*, <strong>Yangyang Xu</strong>, Weiming Wang, Zijun Deng and Pheng-Ann Heng
              <br>
              <em>IEEE TCSVT </em>, 2021   
              <br>
              <a href="https://ieeexplore.ieee.org/document/9606888">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr> 





     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/gagcn.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Transductive Zero-shot Action Recognition via Visually-connected Graph Convolutional Networks  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Chu Han, Jing Qin, Xuemiao Xu*, Guoqiang Han, and Shengfeng He*
              <br>
              <em>IEEE TNNLS </em>, 2020   
              <br>
              <a href="https://ieeexplore.ieee.org/document/9173643">PDF</a> / 
              Supp / 
              <a href="https://github.com/cnnlstm/GAGCN">Code</a>  
              <p></p>
            </td>
     </tr>     
     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/da.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Unsupervised Domain Adaptation via Importance Sampling  </papertitle>
              </a>
              <br>
              Xuemiao Xu, Hai He, Huaidong Zhang, <strong>Yangyang Xu</strong>, and Shengfeng He*
              <br>
              <em>IEEE TCSVT </em>, 2019   
              <br>
              <a href="https://ieeexplore.ieee.org/document/8946732">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr>     
     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/spl.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Ensemble One-Dimensional Convolution Neural Networks for Skeleton-Based Action Recognition  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Jun Cheng, Lei Wang*, Feng Liu and Dapeng Tao
              <br>
              <em>IEEE SPL </em>, 2018   
              <br>
              <a href="https://ieeexplore.ieee.org/document/8368136">PDF</a> / 
              Supp /
              <a href="https://github.com/cnnlstm/Ensem-NN">Code</a> / 

              
              <p></p>
            </td>
     </tr> 


     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/access.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Human Action Recognition by Learning Spatio-Temporal Features With Deep Neural Networks  </papertitle>
              </a>
              <br>
              Lei Wang, <strong>Yangyang Xu</strong>, Jun Cheng*, Jianqin Yin and Jiaji Wu
              <br>
              <em> IEEE Access </em>, 2018   
              <br>
              <a href="https://ieeexplore.ieee.org/document/8319974">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr> 
     <tr >
            <td style="padding:20px;width:25%;vertical-align:middle">
             <img src='images/dta.png' width="160"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> DTA: Double LSTM with temporal-wise attention network for action recognition
                  </papertitle>
              </a>
              <br>
              <strong>Yangyang Xu</strong>, Lei Wang*, Jun Cheng and Jiaji Wu
              <br>
              <em> ICCC </em>, 2017   
              <br>
              <a href="https://ieeexplore.ieee.org/document/8322825">PDF</a> / 
              Supp / 
              Code 
              <p></p>
            </td>
     </tr> 
  </table>


<!-- <heading>Activates</heading> -->



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<tr>
  <td>
    <heading>Activates      </heading>
    <h3> Reviewer </h3>
      <ul>
        <li> 
        <em><strong>SIGGRAPH</em></strong> 2022, <em><strong>SIGGRAPH Asia</em></strong> 2022, <em><strong>NeurIPS</em></strong> 2022, <em><strong>ICML</em></strong> 2022, <em><strong>CVPR</em></strong> 2022, <em><strong>ICCV</em></strong> 2021, <em><strong>CVPR</em></strong> 2021, <em><strong>AAAI</em></strong> 2021, <em><strong>ECCV</em></strong> 2020, <em><strong>CVPR</em></strong> 2020, <em><strong>P&G</em></strong> 2020.
        </li>
        <li> <em><strong>IEEE TIP</em></strong>, <em><strong>IEEE TNNLS</em></strong>, <em>Pattern Recognition</em>, <em>Neural Computing</em>, <em><strong>IEEE SPL</em></strong>. 
        </li>


      </ul>
    <h3> Seminar Report </h3>
    <ul>
    <li>
    <i>Graph Convolutional Neural Networks for Zero-shot Action Recognition</i> <br>
    at City University of Hong Kong, Hong Kong. Dec.2018. 
    </li>
    </ul>
    <h3> Volunteer </h3>
    <ul>
    <li>
    <strong>Chinagraph</strong> 2018    </li>
    </ul>

 </td>
</tr>
</tbody></table>  




</body>



<!-- 
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=blF5spZRsy-BsLpewHTAWHqoFRbmkufiPMrtnO_RFrg&cl=ffffff&w=a"></script>    --> 
<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?yangyangxu"
border="0" alt="Hit Counters"></a>
<br><a href="https://www.easycounter.com/">Web Site Hit Counter</a>
<div>
  <p><center><font face="Arial">
        <br>
            &copy; Yangyang Xu | Last updated: June. 2022.
        </font></center></p>


   
</div>
</body></html>
</html>
